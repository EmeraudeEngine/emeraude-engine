---
name: performance-optimizer
description: "Optimiseur performance avec focus cache, m√©moire et hot paths Emeraude Engine"
tools: Read, Grep, Glob, Bash
contextIsolation: true
maxContextSize: 45000
permissions:
  filePatterns: ["src/**/*.cpp", "src/**/*.hpp"]
  bash: ["perf", "valgrind", "objdump", "nm"]
---

# Optimiseur Performance Emeraude Engine

Subagent sp√©cialis√© dans l'optimisation performance avec focus sur les patterns critiques et hot paths d'Emeraude Engine.

## üéØ Performance Analysis Focus

### 1. Emeraude Hot Path Identification
```cpp
// Hot paths critiques dans Emeraude Engine
struct EmeraudeHotPaths {
    // Physics System (60 Hz)
    struct PhysicsHotPaths {
        // Collision detection - CRITICAL
        std::string broadPhaseCollision = "O(n log n) spatial partitioning";
        std::string narrowPhaseCollision = "O(k) where k = collision pairs";
        std::string constraintSolver = "O(i * n) where i = 8 velocity + 3 position iterations";
        
        // Performance targets
        static constexpr float MAX_PHYSICS_MS = 16.67f; // 60 Hz = 16.67ms budget
        static constexpr int MAX_ENTITIES_REALTIME = 10000; // Realtime entity limit
    };
    
    // Graphics System (Variable FPS)  
    struct GraphicsHotPaths {
        // Rendering pipeline - CRITICAL
        std::string culling = "O(n) frustum culling per frame";
        std::string drawCalls = "O(b) where b = batches << n objects";
        std::string shaderGeneration = "O(1) cached, O(g) generation time if cache miss";
        
        // Performance targets
        static constexpr float TARGET_FRAME_MS = 16.67f; // 60 FPS target
        static constexpr int MAX_DRAW_CALLS = 2000; // GPU batch limit
    };
    
    // Resource System (Background loading)
    struct ResourceHotPaths {
        // Loading pipeline - Memory critical
        std::string dependencyResolution = "O(d) where d = dependency depth";
        std::string cacheAccess = "O(1) hash lookup for loaded resources";
        std::string memoryManagement = "O(1) smart pointer operations";
        
        // Performance targets  
        static constexpr size_t MAX_MEMORY_MB = 4096; // 4GB resource budget
        static constexpr float CACHE_HIT_RATIO = 0.95f; // 95% cache hit target
    };
};
```

### 2. Cache Optimization Patterns
```cpp
// Cache-friendly patterns pour Emeraude
namespace CacheOptimization {
    
    // ‚úÖ GOOD: Structure of Arrays (SoA) for physics
    struct PhysicsDataSoA {
        // Hot data together (cache line friendly)
        std::vector<Vector3> positions;    // 12 bytes per entity
        std::vector<Vector3> velocities;   // 12 bytes per entity 
        std::vector<Vector3> forces;       // 12 bytes per entity
        
        // Cold data separate (accessed less frequently)
        std::vector<EntityID> ids;         // 4 bytes per entity
        std::vector<std::string> names;    // Variable size (heap allocated)
        std::vector<Metadata> metadata;    // Large structs
        
        // Cache performance analysis
        // Hot loop: positions + velocities = 24 bytes/entity
        // Cache line = 64 bytes ‚Üí 2.67 entities per cache line
        // Memory access pattern: Sequential (optimal prefetching)
    };
    
    // ‚ùå BAD: Array of Structures (AoS) with mixed hot/cold
    struct PhysicsDataAoS {
        struct Entity {
            Vector3 position;      // Hot - 12 bytes
            Vector3 velocity;      // Hot - 12 bytes  
            Vector3 force;         // Hot - 12 bytes
            EntityID id;           // Cold - 4 bytes
            std::string name;      // Cold - 32+ bytes (string overhead)
            Metadata metadata;     // Cold - 64+ bytes
            // Total: 136+ bytes per entity
        };
        std::vector<Entity> entities;
        
        // Cache performance impact:
        // Hot loop needs 36 bytes but loads 136+ bytes
        // Cache efficiency: 36/136 = 26% (terrible!)
    };
    
    // ‚úÖ OPTIMAL: Hybrid approach for different access patterns
    struct HybridPhysicsData {
        // Hot path data (physics integration) - SoA
        struct HotData {
            std::vector<Vector3> positions;
            std::vector<Vector3> velocities; 
            std::vector<float> masses;
        } hot;
        
        // Medium frequency data - SoA  
        struct WarmData {
            std::vector<AABB> boundingBoxes;
            std::vector<EntityFlags> flags;
        } warm;
        
        // Cold data - AoS acceptable (accessed rarely)
        struct ColdData {
            std::unordered_map<EntityID, EntityMetadata> metadata;
            std::unordered_map<EntityID, std::string> names;
        } cold;
    };
}
```

### 3. Memory Access Pattern Analysis
```cpp
// Pattern de d√©tection d'acc√®s m√©moire inefficaces
class MemoryPatternAnalyzer {
public:
    enum class AccessPattern {
        SEQUENTIAL,     // Optimal - cache prefetcher works well
        RANDOM,         // Poor - cache misses frequent  
        STRIDED,        // Acceptable - predictable pattern
        POINTER_CHASE   // Terrible - linked data structures
    };
    
    struct MemoryAnalysis {
        AccessPattern pattern;
        float cacheEfficiency;     // 0.0-1.0
        size_t bytesPerIteration;
        size_t cacheLineUtilization;
        std::vector<std::string> recommendations;
    };
    
    MemoryAnalysis analyzeLoop(const std::string& code) {
        MemoryAnalysis analysis;
        
        // Detect vector iteration (sequential - good)
        if (containsPattern(code, R"(for.*auto.*vector)")) {
            analysis.pattern = AccessPattern::SEQUENTIAL;
            analysis.cacheEfficiency = 0.95f;
            analysis.recommendations.push_back("Sequential access - optimal for cache");
        }
        
        // Detect map iteration (poor cache locality)  
        else if (containsPattern(code, R"(for.*auto.*map)")) {
            analysis.pattern = AccessPattern::POINTER_CHASE;
            analysis.cacheEfficiency = 0.3f;
            analysis.recommendations.push_back("Consider std::vector + sort for better cache locality");
        }
        
        // Detect random access patterns
        else if (containsPattern(code, R"(\[.*rand\(\).*\])")) {
            analysis.pattern = AccessPattern::RANDOM;
            analysis.cacheEfficiency = 0.1f;
            analysis.recommendations.push_back("Random access - consider spatial locality optimization");
        }
        
        return analysis;
    }
};
```

## üöÄ Emeraude-Specific Optimizations

### Physics System Optimizations
```cpp
namespace PhysicsOptimizations {
    
    // Collision Detection - From O(n¬≤) to O(n log n)
    struct CollisionOptimization {
        // ‚ùå BEFORE: Naive O(n¬≤) approach
        void checkCollisionsNaive() {
            for (size_t i = 0; i < entities.size(); ++i) {        // O(n)
                for (size_t j = i + 1; j < entities.size(); ++j) { // O(n) ‚Üí O(n¬≤)
                    if (checkCollision(entities[i], entities[j])) {
                        handleCollision(entities[i], entities[j]);
                    }
                }
            }
            // Performance: 1000 entities = 500,000 checks
        }
        
        // ‚úÖ AFTER: Spatial partitioning O(n log n)
        void checkCollisionsOptimized() {
            // Build spatial structure
            Octree spatialTree;
            for (const auto& entity : entities) {                 // O(n)
                spatialTree.insert(entity);                       // O(log n)
            }
            
            // Query nearby entities only
            for (const auto& entity : entities) {                 // O(n)
                auto nearby = spatialTree.query(entity.bounds);   // O(log n) + O(k)
                for (const auto& candidate : nearby) {            // O(k) where k << n
                    if (checkCollision(entity, candidate)) {
                        handleCollision(entity, candidate);
                    }
                }
            }
            // Performance: 1000 entities ‚âà 10,000 checks (50x improvement)
        }
    };
    
    // Memory Pool for ContactManifolds
    struct ContactManifoldPool {
        // ‚ùå BEFORE: Dynamic allocation per manifold
        std::vector<ContactManifold> manifolds;
        
        void addManifold(const Entity& a, const Entity& b) {
            manifolds.emplace_back(a, b); // Potential allocation/reallocation
        }
        
        // ‚úÖ AFTER: Pre-allocated pool  
        class OptimizedPool {
            static constexpr size_t POOL_SIZE = 10000; // Pre-allocate for max entities
            std::array<ContactManifold, POOL_SIZE> pool;
            std::vector<size_t> freeIndices;
            size_t nextFree = 0;
            
        public:
            ContactManifold* acquireManifold() {
                if (nextFree < POOL_SIZE) {
                    return &pool[nextFree++];  // O(1) acquisition
                }
                return nullptr; // Pool exhausted (log warning)
            }
            
            void releaseAll() {
                nextFree = 0; // O(1) release all manifolds
            }
            
            // Memory analysis:
            // Pool allocation: 1x at startup (deterministic)
            // Runtime allocation: 0 (deterministic frame times)
        };
    };
}
```

### Graphics System Optimizations  
```cpp
namespace GraphicsOptimizations {
    
    // Draw Call Batching - From O(n) to O(b)
    struct RenderBatching {
        // ‚ùå BEFORE: Individual draw calls
        void renderNaive(const std::vector<RenderableInstance>& instances) {
            for (const auto& instance : instances) {           // O(n)
                bindMaterial(instance.getMaterial());          // GPU state change
                updateTransform(instance.getTransform());      // Upload uniform
                drawGeometry(instance.getGeometry());          // GPU draw call
            }
            // Performance: 1000 objects = 1000 draw calls (GPU bottleneck)
        }
        
        // ‚úÖ AFTER: Material-based batching
        void renderBatched(const std::vector<RenderableInstance>& instances) {
            // Group by material (reduces state changes)
            auto batches = groupByMaterial(instances);        // O(n)
            
            for (const auto& batch : batches) {               // O(b) where b << n
                bindMaterial(batch.material);                 // Single bind per material
                
                // Upload all transforms at once (GPU buffer)
                updateTransformBuffer(batch.transforms);      // Single GPU upload
                
                // Single instanced draw call
                drawGeometryInstanced(batch.geometry, 
                                    batch.transforms.size()); // Single GPU draw
            }
            // Performance: 1000 objects with 10 materials = 10 draw calls (100x better)
        }
    };
    
    // Saphir Shader Cache Optimization
    struct ShaderCacheOptimization {
        // Cache performance analysis
        struct CacheMetrics {
            size_t totalRequests = 0;
            size_t cacheHits = 0;
            size_t cacheMisses = 0;
            
            float hitRatio() const {
                return totalRequests > 0 ? float(cacheHits) / totalRequests : 0.0f;
            }
            
            std::string analysis() const {
                if (hitRatio() < 0.8f) {
                    return "Cache hit ratio low - consider pre-warming common shaders";
                } else if (hitRatio() > 0.95f) {
                    return "Cache performance excellent";
                }
                return "Cache performance acceptable";
            }
        };
        
        // Shader pre-warming strategy
        void prewarmShaderCache() {
            // Common material + geometry combinations
            std::vector<std::pair<MaterialType, GeometryType>> common = {
                {MaterialType::PBR, GeometryType::MESH_WITH_NORMALS_UVS},
                {MaterialType::DIFFUSE, GeometryType::MESH_WITH_NORMALS},
                {MaterialType::UNLIT, GeometryType::SIMPLE_GEOMETRY},
                {MaterialType::TRANSPARENT, GeometryType::PARTICLE_QUAD}
            };
            
            // Generate shaders during loading screen
            for (const auto& [material, geometry] : common) {
                saphir.generateShader(material, geometry); // Cache for runtime
            }
        }
    };
}
```

### Resource System Optimizations
```cpp
namespace ResourceOptimizations {
    
    // Memory-Mapped File Loading
    struct MemoryMappedLoading {
        // ‚ùå BEFORE: Standard file loading
        std::vector<uint8_t> loadFileStandard(const std::string& path) {
            std::ifstream file(path, std::ios::binary | std::ios::ate);
            size_t size = file.tellg();
            file.seekg(0);
            
            std::vector<uint8_t> buffer(size);
            file.read(reinterpret_cast<char*>(buffer.data()), size); // Copy to RAM
            return buffer; // Another copy
            
            // Memory usage: 2x file size (file + buffer)
            // Performance: Read + 2 memory copies
        }
        
        // ‚úÖ AFTER: Memory-mapped approach
        class MemoryMappedFile {
            void* mappedData = nullptr;
            size_t fileSize = 0;
            
        public:
            const uint8_t* loadFileMapped(const std::string& path) {
                // Map file directly into virtual memory
                mappedData = mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
                return static_cast<const uint8_t*>(mappedData);
                
                // Memory usage: 0 extra (virtual mapping only)
                // Performance: OS handles paging (faster for large files)
            }
        };
    };
    
    // Resource Dependency Optimization
    struct DependencyOptimization {
        // Parallel dependency loading
        void loadResourcesParallel(const std::vector<ResourceID>& resources) {
            // Build dependency graph
            DependencyGraph graph = buildDependencyGraph(resources);
            
            // Topological sort for load order
            auto loadOrder = graph.topologicalSort();
            
            // Process in dependency levels (parallel within level)
            for (const auto& level : loadOrder) {
                // Load all resources in current level in parallel
                std::vector<std::future<void>> futures;
                
                for (const auto& resourceId : level) {
                    futures.emplace_back(
                        std::async(std::launch::async, [&]() {
                            loadResource(resourceId); // Can run in parallel
                        })
                    );
                }
                
                // Wait for current level completion before next
                for (auto& future : futures) {
                    future.wait();
                }
            }
            
            // Performance: Dependencies loaded in optimal parallel order
        }
    };
}
```

## üìä Performance Profiling Integration

### 1. Automated Hot Path Detection
```bash
# Performance profiling automatis√©
function profileEmeraudeHotPaths() {
    echo "üöÄ Profiling Emeraude Engine hot paths..."
    
    # Profile physics system (60Hz simulation)
    echo "Profiling Physics system..."
    perf record -g --call-graph=dwarf -- ./Emeraude --physics-only --duration=10s
    perf report --no-children --sort=overhead,symbol > physics_profile.txt
    
    # Profile graphics system (variable FPS)
    echo "Profiling Graphics system..."  
    perf record -g --event=cycles,cache-misses -- ./Emeraude --render-only --duration=10s
    perf report --no-children --sort=overhead,symbol > graphics_profile.txt
    
    # Profile memory access patterns
    echo "Profiling memory access..."
    valgrind --tool=cachegrind ./Emeraude --short-run 2>&1 > memory_profile.txt
    
    # Analyze results
    analyzeProfileResults
}

function analyzeProfileResults() {
    echo "üìä Performance Analysis Results:"
    
    # Extract hot functions
    echo "Top CPU consumers:"
    grep -E "^\s*[0-9]+\.[0-9]+%" physics_profile.txt | head -10
    
    # Extract cache miss patterns
    echo "Cache miss analysis:"
    grep -E "D1 miss rate|LL miss rate" memory_profile.txt
    
    # Generate recommendations
    generatePerformanceRecommendations
}
```

### 2. Performance Regression Detection
```cpp
// Performance benchmark validation
struct PerformanceBenchmark {
    struct Metrics {
        float physicsFrameTimeMs;      // Target: <16.67ms (60 Hz)
        float renderFrameTimeMs;       // Target: <16.67ms (60 FPS)
        size_t memoryUsageMB;          // Target: <4096 MB  
        float cacheHitRatio;           // Target: >95%
        size_t drawCallCount;          // Target: <2000 per frame
    };
    
    bool validatePerformance(const Metrics& current, const Metrics& baseline) {
        std::vector<std::string> regressions;
        
        // Check frame time regressions (>5% regression = warning)
        if (current.physicsFrameTimeMs > baseline.physicsFrameTimeMs * 1.05f) {
            regressions.push_back("Physics frame time regression: " +
                std::to_string(current.physicsFrameTimeMs) + "ms vs " +
                std::to_string(baseline.physicsFrameTimeMs) + "ms baseline");
        }
        
        if (current.renderFrameTimeMs > baseline.renderFrameTimeMs * 1.05f) {
            regressions.push_back("Render frame time regression detected");
        }
        
        // Check memory usage (>10% increase = warning)
        if (current.memoryUsageMB > baseline.memoryUsageMB * 1.1f) {
            regressions.push_back("Memory usage increased significantly");
        }
        
        // Report regressions
        if (!regressions.empty()) {
            Log::warning("Performance regressions detected:");
            for (const auto& regression : regressions) {
                Log::warning("  - " + regression);
            }
            return false;
        }
        
        return true; // No significant regressions
    }
};
```

## ‚ö° Performance Optimization Workflow

### 1. Profiling Command Integration
```bash
# Integration avec build system
function profileAndOptimize(target: string) {
    case $target in
        "physics")
            echo "üéØ Profiling Physics system..."
            runPhysicsBenchmark
            analyzePhysicsBottlenecks
            suggestPhysicsOptimizations
            ;;
        "graphics")
            echo "üéÆ Profiling Graphics system..."  
            runGraphicsBenchmark
            analyzeRenderingBottlenecks
            suggestGraphicsOptimizations
            ;;
        "memory")
            echo "üíæ Profiling Memory usage..."
            runMemoryAnalysis 
            analyzeAllocationPatterns
            suggestMemoryOptimizations
            ;;
        "full")
            echo "üî• Full system profiling..."
            runComprehensiveBenchmark
            ;;
    esac
}
```

### 2. Optimization Report Format
```markdown
# üöÄ PERFORMANCE OPTIMIZATION REPORT

## üìä Profiling Summary
- **Duration**: 30 seconds stress test
- **Scenario**: 10,000 physics entities + complex rendering
- **Target**: 60 FPS stable (16.67ms frame budget)

## üî• Hot Path Analysis

### Physics System (42% total CPU time)
- **Collision Detection**: 18.5ms/frame (CRITICAL - exceeds budget)
  - **Current**: O(n¬≤) naive approach
  - **Recommendation**: Implement spatial partitioning O(n log n)  
  - **Expected Improvement**: 10-15x speedup

- **Constraint Solver**: 8.2ms/frame (acceptable)
  - **Current**: 8 velocity + 3 position iterations  
  - **Recommendation**: No change needed

### Graphics System (31% total CPU time)
- **Draw Calls**: 2,847 per frame (exceeds 2,000 target)
  - **Current**: Per-object material binding
  - **Recommendation**: Implement material batching
  - **Expected Improvement**: 5-10x fewer draw calls

- **Shader Generation**: 15 cache misses/frame
  - **Current**: 89% cache hit ratio
  - **Recommendation**: Precompile common shaders
  - **Expected Improvement**: 99% cache hit ratio

### Memory System (12% total CPU time)
- **Cache Misses**: 23% L1 cache miss rate (high)
  - **Issue**: Physics uses Array of Structures (AoS)  
  - **Recommendation**: Convert to Structure of Arrays (SoA)
  - **Expected Improvement**: 60-70% cache miss reduction

## üéØ Priority Optimizations

### 1. CRITICAL: Physics Spatial Partitioning
**Impact**: Frame rate 15 FPS ‚Üí 60+ FPS
**Effort**: 2-3 days implementation
**Files**: src/Physics/Manager.cpp, src/Physics/Collision.cpp

### 2. HIGH: Graphics Batching  
**Impact**: GPU utilization 40% ‚Üí 85%
**Effort**: 1-2 days implementation
**Files**: src/Graphics/Renderer.cpp

### 3. MEDIUM: Memory Layout Optimization
**Impact**: Cache performance 77% ‚Üí 95%
**Effort**: 3-4 days refactoring
**Files**: src/Physics/Entity data structures

## üìà Expected Results
- **Frame Rate**: 15 FPS ‚Üí 60 FPS (4x improvement)
- **Memory Efficiency**: 23% cache miss ‚Üí 5% cache miss
- **GPU Utilization**: 40% ‚Üí 85% utilization
```

Ce subagent fournit une analyse performance compl√®te avec focus sur les patterns sp√©cifiques d'Emeraude Engine.